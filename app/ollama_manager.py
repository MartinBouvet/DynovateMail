#!/usr/bin/env python3
"""
Gestionnaire Ollama - VERSION FINALE
"""
import logging
import subprocess
import time
import os
import signal
from typing import Dict, List, Optional

import requests

logger = logging.getLogger(__name__)

class OllamaManager:
    """G√®re le serveur Ollama."""
    
    def __init__(self, base_url: str = "http://localhost:11434", model_name: str = "nchapman/ministral-8b-instruct-2410:8b"):
        self.base_url = base_url
        self.model_name = model_name
        self.process = None
        self.was_already_running = False
    
    def is_running(self) -> bool:
        """V√©rifie si Ollama tourne."""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    
    def ensure_running(self) -> bool:
        """S'assure qu'Ollama tourne."""
        logger.info("üöÄ D√©marrage du serveur Ollama...")
        
        # D√©j√† en cours ?
        if self.is_running():
            logger.info("‚úÖ Ollama est d√©j√† en cours d'ex√©cution")
            self.was_already_running = True
            
            # V√©rifier le mod√®le
            if self.check_model():
                return True
            else:
                logger.warning("‚ö†Ô∏è Mod√®le non trouv√©")
                return False
        
        # D√©marrer Ollama
        logger.info("üîÑ Lancement d'Ollama...")
        
        try:
            # D√©marrer le serveur
            self.process = subprocess.Popen(
                ["ollama", "serve"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
                start_new_session=True
            )
            
            # Attendre le d√©marrage (max 10s)
            for i in range(20):
                time.sleep(0.5)
                if self.is_running():
                    logger.info("‚úÖ Ollama d√©marr√© avec succ√®s")
                    
                    # V√©rifier le mod√®le
                    if self.check_model():
                        return True
                    else:
                        logger.warning("‚ö†Ô∏è Mod√®le non trouv√©")
                        return False
            
            logger.error("‚ùå Timeout d√©marrage Ollama")
            return False
        
        except FileNotFoundError:
            logger.error("‚ùå Ollama non install√©")
            return False
        
        except Exception as e:
            logger.error(f"‚ùå Erreur d√©marrage: {e}")
            return False
    
    def check_model(self) -> bool:
        """V√©rifie que le mod√®le est disponible."""
        logger.info(f"üîç V√©rification du mod√®le {self.model_name}...")
        
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                models = data.get('models', [])
                
                for model in models:
                    if model.get('name') == self.model_name:
                        logger.info(f"‚úÖ Mod√®le {self.model_name} trouv√© et pr√™t")
                        return True
                
                logger.warning(f"‚ö†Ô∏è Mod√®le {self.model_name} non trouv√©")
                logger.info("üì• T√©l√©chargez-le avec: ollama pull nchapman/ministral-8b-instruct-2410:8b")
                return False
            
            return False
        
        except Exception as e:
            logger.error(f"‚ùå Erreur v√©rification mod√®le: {e}")
            return False
    
    def get_status(self) -> Dict:
        """Retourne le statut d'Ollama."""
        status = {
            'running': self.is_running(),
            'base_url': self.base_url,
            'model_name': self.model_name,
            'available_models': []
        }
        
        if status['running']:
            try:
                response = requests.get(f"{self.base_url}/api/tags", timeout=3)
                if response.status_code == 200:
                    data = response.json()
                    status['available_models'] = [m['name'] for m in data.get('models', [])]
            except:
                pass
        
        return status
    
    def list_models(self) -> List[str]:
        """Liste les mod√®les disponibles."""
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=3)
            if response.status_code == 200:
                data = response.json()
                return [m['name'] for m in data.get('models', [])]
        except:
            pass
        
        return []
    
    def pull_model(self, model_name: str = None) -> bool:
        """T√©l√©charge un mod√®le."""
        if model_name is None:
            model_name = self.model_name
        
        logger.info(f"üì• T√©l√©chargement du mod√®le {model_name}...")
        
        try:
            subprocess.run(
                ["ollama", "pull", model_name],
                check=True,
                capture_output=True,
                text=True
            )
            
            logger.info(f"‚úÖ Mod√®le {model_name} t√©l√©charg√©")
            return True
        
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Erreur t√©l√©chargement: {e}")
            return False
        
        except Exception as e:
            logger.error(f"‚ùå Erreur: {e}")
            return False
    
    def stop(self):
        """Arr√™te Ollama si on l'a d√©marr√©."""
        if self.process and not self.was_already_running:
            logger.info("üõë Arr√™t d'Ollama...")
            try:
                os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)
                self.process.wait(timeout=5)
                logger.info("‚úÖ Ollama arr√™t√©")
            except:
                logger.warning("‚ö†Ô∏è Impossible d'arr√™ter Ollama proprement")
        else:
            logger.info("‚ÑπÔ∏è Ollama √©tait d√©j√† en cours, on ne l'arr√™te pas")
    
    def cleanup(self):
        """Nettoyage √† la fermeture."""
        self.stop()
    
    def __del__(self):
        """Destructeur."""
        self.cleanup()