#!/usr/bin/env python3
"""
Gestionnaire Ollama - Lance et arrÃªte automatiquement le serveur
VERSION SIMPLIFIÃ‰E sans psutil
"""
import logging
import subprocess
import time
import requests
import os
import signal
import platform
from typing import Optional

logger = logging.getLogger(__name__)

class OllamaManager:
    """GÃ¨re le cycle de vie du serveur Ollama."""
    
    def __init__(self, model_name: str = "nchapman/ministral-8b-instruct-2410:8b"):
        """
        Initialise le gestionnaire Ollama.
        
        Args:
            model_name: Nom du modÃ¨le Ã  utiliser
        """
        self.model_name = model_name
        self.base_url = "http://localhost:11434"
        self.process: Optional[subprocess.Popen] = None
        self.was_already_running = False
        self.system = platform.system()
        
    def start(self) -> bool:
        """
        DÃ©marre Ollama si nÃ©cessaire.
        
        Returns:
            True si Ollama est prÃªt, False sinon
        """
        logger.info("ðŸš€ DÃ©marrage du serveur Ollama...")
        
        # VÃ©rifier si Ollama est dÃ©jÃ  en cours d'exÃ©cution
        if self._is_running():
            logger.info("âœ… Ollama est dÃ©jÃ  en cours d'exÃ©cution")
            self.was_already_running = True
            return self._verify_model_loaded()
        
        # Lancer Ollama
        try:
            logger.info("ðŸ”„ Lancement du serveur Ollama...")
            
            # DÃ©terminer la commande selon l'OS
            if self.system == 'Windows':
                # Windows
                self.process = subprocess.Popen(
                    ['ollama', 'serve'],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0
                )
            elif self.system == 'Darwin':
                # macOS
                self.process = subprocess.Popen(
                    ['ollama', 'serve'],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    start_new_session=True
                )
            else:
                # Linux
                self.process = subprocess.Popen(
                    ['ollama', 'serve'],
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.DEVNULL,
                    preexec_fn=os.setsid
                )
            
            # Attendre que le serveur soit prÃªt (max 30 secondes)
            print("â³ Attente du dÃ©marrage d'Ollama", end="", flush=True)
            for i in range(30):
                time.sleep(1)
                print(".", end="", flush=True)
                if self._is_running():
                    print(f" âœ… DÃ©marrÃ© en {i+1}s")
                    logger.info(f"âœ… Serveur Ollama dÃ©marrÃ© aprÃ¨s {i+1}s")
                    return self._verify_model_loaded()
            
            print(" âŒ Timeout")
            logger.error("âŒ Timeout: Ollama n'a pas dÃ©marrÃ© en 30s")
            return False
            
        except FileNotFoundError:
            logger.error("âŒ Ollama n'est pas installÃ© ou pas dans le PATH")
            print("\nâŒ ERREUR: Ollama n'est pas installÃ©")
            print("ðŸ“¥ Installez Ollama depuis: https://ollama.ai")
            print("\nðŸ’¡ Sur macOS, utilisez: brew install ollama")
            return False
        except Exception as e:
            logger.error(f"âŒ Erreur lors du lancement d'Ollama: {e}")
            return False
    
    def _is_running(self) -> bool:
        """
        VÃ©rifie si Ollama est en cours d'exÃ©cution.
        
        Returns:
            True si Ollama rÃ©pond, False sinon
        """
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=2)
            return response.status_code == 200
        except:
            return False
    
    def _verify_model_loaded(self) -> bool:
        """
        VÃ©rifie que le modÃ¨le est disponible.
        
        Returns:
            True si le modÃ¨le est prÃªt, False sinon
        """
        try:
            logger.info(f"ðŸ” VÃ©rification du modÃ¨le {self.model_name}...")
            
            # Lister les modÃ¨les disponibles
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                model_names = [m.get('name', '') for m in models]
                
                # VÃ©rifier si notre modÃ¨le est dans la liste
                if self.model_name in model_names:
                    logger.info(f"âœ… ModÃ¨le {self.model_name} trouvÃ© et prÃªt")
                    return True
                else:
                    logger.warning(f"âš ï¸ ModÃ¨le {self.model_name} non trouvÃ©")
                    print(f"\nâš ï¸ ModÃ¨le {self.model_name} non trouvÃ©")
                    print(f"ðŸ“‹ ModÃ¨les disponibles: {', '.join(model_names) if model_names else 'Aucun'}")
                    print(f"\nðŸ’¡ Pour installer le modÃ¨le, lancez:")
                    print(f"   ollama pull {self.model_name}")
                    return False
            else:
                logger.error(f"âŒ Impossible de lister les modÃ¨les: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Erreur vÃ©rification modÃ¨le: {e}")
            return False
    
    def stop(self):
        """ArrÃªte Ollama s'il a Ã©tÃ© lancÃ© par cette application."""
        if self.was_already_running:
            logger.info("â„¹ï¸ Ollama Ã©tait dÃ©jÃ  en cours, on ne l'arrÃªte pas")
            return
        
        if self.process is None:
            logger.info("â„¹ï¸ Aucun processus Ollama Ã  arrÃªter")
            return
        
        try:
            logger.info("ðŸ›‘ ArrÃªt du serveur Ollama...")
            
            # ArrÃªt selon l'OS
            if self.system == 'Windows':
                self.process.terminate()
            else:
                # macOS et Linux
                try:
                    if self.system == 'Darwin':
                        # macOS - terminer le groupe de processus
                        os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)
                    else:
                        # Linux
                        os.killpg(os.getpgid(self.process.pid), signal.SIGTERM)
                except:
                    # Fallback: terminer juste le processus principal
                    self.process.terminate()
            
            # Attendre l'arrÃªt (max 5 secondes)
            try:
                self.process.wait(timeout=5)
                logger.info("âœ… Ollama arrÃªtÃ© proprement")
            except subprocess.TimeoutExpired:
                # Forcer l'arrÃªt si nÃ©cessaire
                self.process.kill()
                logger.warning("âš ï¸ Ollama arrÃªtÃ© de force")
            
            self.process = None
            
        except Exception as e:
            logger.error(f"âŒ Erreur lors de l'arrÃªt d'Ollama: {e}")
    
    def get_status(self) -> dict:
        """
        Obtient le statut d'Ollama.
        
        Returns:
            Dict avec les infos de statut
        """
        status = {
            "running": self._is_running(),
            "model_name": self.model_name,
            "base_url": self.base_url,
            "was_already_running": self.was_already_running,
            "system": self.system
        }
        
        if status["running"]:
            try:
                response = requests.get(f"{self.base_url}/api/tags", timeout=2)
                if response.status_code == 200:
                    models = response.json().get('models', [])
                    status["available_models"] = [m.get('name', '') for m in models]
            except:
                pass
        
        return status
    
    def __enter__(self):
        """Support du context manager."""
        self.start()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Support du context manager."""
        self.stop()