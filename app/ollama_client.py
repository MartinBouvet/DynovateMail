#!/usr/bin/env python3
"""
Client Ollama - VERSION COMPL√àTE CORRIG√âE
"""
import logging
import requests
from typing import Optional, Dict, List

logger = logging.getLogger(__name__)

class OllamaClient:
    """
    Client pour interagir avec le serveur Ollama.
    
    Permet de g√©n√©rer du texte avec des mod√®les IA locaux via l'API Ollama.
    """
    
    def __init__(self, base_url: str = "http://localhost:11434", 
                 model: str = "nchapman/ministral-8b-instruct-2410:8b"):
        """
        Initialise le client Ollama.
        
        Args:
            base_url: URL du serveur Ollama
            model: Nom du mod√®le √† utiliser
        """
        self.base_url = base_url
        self.model = model
        self.session = requests.Session()
        self.session.headers.update({
            'Content-Type': 'application/json'
        })
        
        logger.info(f"‚úÖ Ollama connect√© sur {base_url}")
    
    def is_available(self) -> bool:
        """
        V√©rifie si le serveur Ollama est disponible.
        
        Returns:
            True si Ollama est accessible, False sinon
        """
        try:
            response = self.session.get(
                f"{self.base_url}/api/tags",
                timeout=2
            )
            return response.status_code == 200
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Ollama non disponible: {e}")
            return False
        except Exception as e:
            logger.error(f"‚ùå Erreur inattendue: {e}")
            return False
    
    def get_models(self) -> List[str]:
        """
        R√©cup√®re la liste des mod√®les disponibles.
        
        Returns:
            Liste des noms de mod√®les disponibles
        """
        try:
            response = self.session.get(
                f"{self.base_url}/api/tags",
                timeout=5
            )
            
            if response.status_code == 200:
                data = response.json()
                models = [model['name'] for model in data.get('models', [])]
                logger.info(f"üìö {len(models)} mod√®les disponibles")
                return models
            else:
                logger.error(f"‚ùå Erreur r√©cup√©ration mod√®les: {response.status_code}")
                return []
        
        except Exception as e:
            logger.error(f"‚ùå Erreur get_models: {e}")
            return []
    
    def generate(self, prompt: str, system_prompt: Optional[str] = None, 
                 temperature: float = 0.7, max_tokens: int = 500) -> Optional[str]:
        """
        G√©n√®re une r√©ponse avec Ollama.
        
        Args:
            prompt: Texte d'entr√©e pour la g√©n√©ration
            system_prompt: Instructions syst√®me optionnelles
            temperature: Contr√¥le la cr√©ativit√© (0.0 = d√©terministe, 1.0 = cr√©atif)
            max_tokens: Nombre maximum de tokens √† g√©n√©rer
            
        Returns:
            Texte g√©n√©r√© ou None en cas d'erreur
        """
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_tokens
                }
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            logger.debug(f"ü§ñ G√©n√©ration avec {self.model}...")
            
            response = self.session.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get("response", "")
                
                if generated_text:
                    logger.info(f"‚úÖ R√©ponse g√©n√©r√©e ({len(generated_text)} caract√®res)")
                    return generated_text
                else:
                    logger.warning("‚ö†Ô∏è R√©ponse vide de Ollama")
                    return None
            else:
                logger.error(f"‚ùå Erreur API Ollama: {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("‚ùå Timeout lors de la g√©n√©ration")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erreur r√©seau: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration Ollama: {e}")
            return None
    
    def chat(self, messages: List[Dict[str, str]], 
             temperature: float = 0.7, max_tokens: int = 500) -> Optional[str]:
        """
        Mode chat avec historique de conversation.
        
        Args:
            messages: Liste de messages au format [{"role": "user/assistant", "content": "..."}]
            temperature: Contr√¥le la cr√©ativit√©
            max_tokens: Nombre maximum de tokens
            
        Returns:
            R√©ponse de l'assistant ou None en cas d'erreur
        """
        try:
            payload = {
                "model": self.model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_tokens
                }
            }
            
            logger.debug(f"üí¨ Chat avec {len(messages)} messages")
            
            response = self.session.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                message = result.get("message", {})
                content = message.get("content", "")
                
                if content:
                    logger.info(f"‚úÖ R√©ponse chat g√©n√©r√©e ({len(content)} caract√®res)")
                    return content
                else:
                    logger.warning("‚ö†Ô∏è R√©ponse chat vide")
                    return None
            else:
                logger.error(f"‚ùå Erreur chat Ollama: {response.status_code}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("‚ùå Timeout lors du chat")
            return None
        except requests.exceptions.RequestException as e:
            logger.error(f"‚ùå Erreur r√©seau chat: {e}")
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur chat Ollama: {e}")
            return None
    
    def analyze_email(self, email_subject: str, email_body: str, sender: str) -> Dict:
        """
        Analyse un email avec l'IA.
        
        Args:
            email_subject: Sujet de l'email
            email_body: Corps de l'email
            sender: Exp√©diteur
            
        Returns:
            Dictionnaire contenant l'analyse
        """
        try:
            # Tronquer le body pour √©viter les timeouts
            body_truncated = email_body[:500] if len(email_body) > 500 else email_body
            
            prompt = f"""Analyse cet email et r√©ponds UNIQUEMENT avec un JSON valide (pas de markdown, pas de backticks):

Sujet: {email_subject}
Exp√©diteur: {sender}
Corps: {body_truncated}

Retourne exactement ce format JSON:
{{
    "category": "cv|meeting|invoice|newsletter|support|spam|general",
    "sentiment": "positive|neutral|negative",
    "urgent": true|false,
    "spam_score": 0.5,
    "summary": "r√©sum√© en une phrase",
    "confidence": 0.8
}}"""

            response = self.generate(
                prompt=prompt,
                temperature=0.3,
                max_tokens=200
            )
            
            if response:
                # Nettoyer la r√©ponse (enlever markdown si pr√©sent)
                response_clean = response.strip()
                
                # Enlever les backticks si pr√©sents
                if response_clean.startswith('```'):
                    lines = response_clean.split('\n')
                    response_clean = '\n'.join(lines[1:-1]) if len(lines) > 2 else response_clean
                
                # Parser le JSON
                import json
                analysis = json.loads(response_clean)
                
                logger.info(f"‚úÖ Email analys√©: {analysis.get('category')}")
                return analysis
            else:
                logger.warning("‚ö†Ô∏è Pas de r√©ponse pour l'analyse email")
                return self._default_analysis()
        
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {e}")
            return self._default_analysis()
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse email: {e}")
            return self._default_analysis()
    
    def _default_analysis(self) -> Dict:
        """
        Retourne une analyse par d√©faut en cas d'erreur.
        
        Returns:
            Analyse par d√©faut
        """
        return {
            "category": "general",
            "sentiment": "neutral",
            "urgent": False,
            "spam_score": 0.0,
            "summary": "Analyse non disponible",
            "confidence": 0.0
        }
    
    def test_connection(self) -> bool:
        """
        Teste la connexion avec Ollama et le mod√®le.
        
        Returns:
            True si tout fonctionne, False sinon
        """
        try:
            if not self.is_available():
                logger.error("‚ùå Serveur Ollama non accessible")
                return False
            
            # Test simple de g√©n√©ration
            response = self.generate(
                prompt="Dis bonjour en un mot.",
                temperature=0.1,
                max_tokens=10
            )
            
            if response:
                logger.info("‚úÖ Test de connexion Ollama r√©ussi")
                return True
            else:
                logger.error("‚ùå Test de g√©n√©ration √©chou√©")
                return False
        
        except Exception as e:
            logger.error(f"‚ùå Erreur test connexion: {e}")
            return False
    
    def __str__(self) -> str:
        """Repr√©sentation textuelle du client."""
        return f"OllamaClient(url={self.base_url}, model={self.model})"
    
    def __repr__(self) -> str:
        """Repr√©sentation d√©taill√©e du client."""
        return f"OllamaClient(base_url={self.base_url}, model={self.model})"