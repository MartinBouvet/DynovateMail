#!/usr/bin/env python3
"""
Client Ollama pour int√©gration IA locale
"""
import logging
import requests
import json
from typing import Optional, Dict, List

logger = logging.getLogger(__name__)

class OllamaClient:
    """Client pour communiquer avec Ollama en local."""
    
    def __init__(self, base_url: str = "http://localhost:11434", model: str = "nchapman/ministral-8b-instruct-2410:8b"):
        """
        Initialise le client Ollama.
        
        Args:
            base_url: URL de base d'Ollama (par d√©faut localhost:11434)
            model: Nom du mod√®le √† utiliser
        """
        self.base_url = base_url
        self.model = model
        self.session = requests.Session()
        self.session.headers.update({'Content-Type': 'application/json'})
        
        # V√©rifier la connexion
        if not self._check_connection():
            logger.warning("‚ö†Ô∏è Ollama n'est pas accessible, v√©rifiez qu'il est lanc√©")
    
    def _check_connection(self) -> bool:
        """V√©rifie que Ollama est accessible."""
        try:
            response = self.session.get(f"{self.base_url}/api/tags", timeout=5)
            if response.status_code == 200:
                logger.info(f"‚úÖ Ollama connect√© sur {self.base_url}")
                return True
            return False
        except Exception as e:
            logger.error(f"‚ùå Impossible de se connecter √† Ollama: {e}")
            return False
    
    def generate(self, prompt: str, system_prompt: Optional[str] = None, temperature: float = 0.7, max_tokens: int = 2000) -> Optional[str]:
        """
        G√©n√®re une r√©ponse avec le mod√®le Ollama.
        
        Args:
            prompt: Texte d'entr√©e
            system_prompt: Instructions syst√®me (optionnel)
            temperature: Cr√©ativit√© (0-1)
            max_tokens: Nombre maximum de tokens
            
        Returns:
            R√©ponse g√©n√©r√©e ou None en cas d'erreur
        """
        try:
            payload = {
                "model": self.model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": temperature,
                    "num_predict": max_tokens
                }
            }
            
            if system_prompt:
                payload["system"] = system_prompt
            
            logger.info(f"ü§ñ G√©n√©ration avec Ollama ({self.model})...")
            
            response = self.session.post(
                f"{self.base_url}/api/generate",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                generated_text = result.get("response", "")
                logger.info(f"‚úÖ R√©ponse g√©n√©r√©e ({len(generated_text)} caract√®res)")
                return generated_text
            else:
                logger.error(f"‚ùå Erreur API Ollama: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration Ollama: {e}")
            return None
    
    def chat(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> Optional[str]:
        """
        Mode chat avec historique de conversation.
        
        Args:
            messages: Liste de messages [{"role": "user/assistant", "content": "..."}]
            temperature: Cr√©ativit√©
            
        Returns:
            R√©ponse de l'assistant
        """
        try:
            payload = {
                "model": self.model,
                "messages": messages,
                "stream": False,
                "options": {
                    "temperature": temperature
                }
            }
            
            response = self.session.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get("message", {}).get("content", "")
            else:
                logger.error(f"‚ùå Erreur chat Ollama: {response.status_code}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur chat Ollama: {e}")
            return None
    
    def analyze_email(self, email_subject: str, email_body: str, sender: str) -> Dict:
        """
        Analyse un email avec l'IA.
        
        Returns:
            Dict avec category, priority, sentiment, summary, suggested_actions
        """
        system_prompt = """Tu es un assistant IA expert en analyse d'emails professionnels.
Ton r√¥le est d'analyser les emails et de fournir des informations structur√©es.
R√©ponds UNIQUEMENT en JSON valide sans texte suppl√©mentaire."""

        prompt = f"""Analyse cet email et retourne un JSON avec ces champs:
- category: une cat√©gorie parmi [cv, rendez-vous, spam, facture, newsletter, important, personnel, autre]
- priority: un niveau parmi [haute, moyenne, basse]
- sentiment: un sentiment parmi [positif, neutre, n√©gatif, urgent]
- summary: un r√©sum√© en 1-2 phrases
- suggested_actions: liste de 2-3 actions sugg√©r√©es
- is_spam: true/false

Email √† analyser:
De: {sender}
Sujet: {email_subject}
Contenu: {email_body[:1000]}

R√©ponds en JSON uniquement."""

        try:
            response = self.generate(prompt, system_prompt=system_prompt, temperature=0.3)
            if response:
                # Nettoyer la r√©ponse pour extraire le JSON
                response = response.strip()
                if response.startswith("```json"):
                    response = response[7:]
                if response.endswith("```"):
                    response = response[:-3]
                response = response.strip()
                
                analysis = json.loads(response)
                logger.info(f"‚úÖ Email analys√©: {analysis.get('category', 'autre')}")
                return analysis
            else:
                return self._default_analysis()
        except Exception as e:
            logger.error(f"‚ùå Erreur analyse email: {e}")
            return self._default_analysis()
    
    def generate_email_response(self, email_subject: str, email_body: str, sender: str, context: str = "") -> Optional[str]:
        """
        G√©n√®re une r√©ponse automatique √† un email.
        
        Args:
            email_subject: Sujet de l'email
            email_body: Corps de l'email
            sender: Exp√©diteur
            context: Contexte suppl√©mentaire
            
        Returns:
            R√©ponse g√©n√©r√©e
        """
        system_prompt = """Tu es un assistant IA professionnel qui g√©n√®re des r√©ponses par email.
Tes r√©ponses doivent √™tre:
- Polies et professionnelles
- Concises (2-4 paragraphes maximum)
- Adapt√©es au contexte
- En fran√ßais correct
- Sign√©es "L'√©quipe Dynovate" """

        prompt = f"""G√©n√®re une r√©ponse professionnelle √† cet email:

De: {sender}
Sujet: {email_subject}
Message: {email_body[:800]}

{f'Contexte: {context}' if context else ''}

G√©n√®re une r√©ponse appropri√©e, claire et professionnelle."""

        return self.generate(prompt, system_prompt=system_prompt, temperature=0.7, max_tokens=500)
    
    def extract_meeting_info(self, email_body: str) -> Optional[Dict]:
        """
        Extrait les informations de rendez-vous d'un email.
        
        Returns:
            Dict avec date, heure, dur√©e, sujet, participants ou None
        """
        system_prompt = """Tu extrais les informations de rendez-vous des emails.
R√©ponds UNIQUEMENT en JSON valide."""

        prompt = f"""Extrait les informations de rendez-vous de cet email.
Retourne un JSON avec: date, heure, duree_minutes, sujet, participants (liste), lieu

Email: {email_body[:1000]}

Si aucun rendez-vous d√©tect√©, retourne {{"has_meeting": false}}
Sinon retourne {{"has_meeting": true, ...autres champs...}}

JSON uniquement:"""

        try:
            response = self.generate(prompt, system_prompt=system_prompt, temperature=0.2)
            if response:
                response = response.strip()
                if response.startswith("```json"):
                    response = response[7:]
                if response.endswith("```"):
                    response = response[:-3]
                response = response.strip()
                
                meeting_info = json.loads(response)
                if meeting_info.get("has_meeting"):
                    logger.info("‚úÖ Rendez-vous d√©tect√© dans l'email")
                    return meeting_info
            return None
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction rendez-vous: {e}")
            return None
    
    def chat_assistant(self, user_message: str, conversation_history: List[Dict] = None) -> str:
        """
        Chatbot assistant intelligent.
        
        Args:
            user_message: Message de l'utilisateur
            conversation_history: Historique de la conversation
            
        Returns:
            R√©ponse du chatbot
        """
        if conversation_history is None:
            conversation_history = []
        
        # Ajouter un message syst√®me au d√©but
        messages = [{
            "role": "system",
            "content": """Tu es l'assistant IA Dynovate, expert en gestion d'emails et productivit√©.
Tu aides les utilisateurs √† g√©rer leurs emails, organiser leur travail et automatiser leurs t√¢ches.
Sois amical, concis et efficace. R√©ponds en fran√ßais."""
        }]
        
        # Ajouter l'historique
        messages.extend(conversation_history)
        
        # Ajouter le nouveau message
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        response = self.chat(messages, temperature=0.8)
        return response if response else "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse."
    
    def _default_analysis(self) -> Dict:
        """Retourne une analyse par d√©faut en cas d'erreur."""
        return {
            "category": "autre",
            "priority": "moyenne",
            "sentiment": "neutre",
            "summary": "Analyse non disponible",
            "suggested_actions": ["Lire l'email"],
            "is_spam": False
        }